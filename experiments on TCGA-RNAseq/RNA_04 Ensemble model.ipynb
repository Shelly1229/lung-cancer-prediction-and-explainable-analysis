{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing \n",
    "from category_encoders import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, f1_score, precision_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn import datasets, linear_model, metrics\n",
    "from sklearn.metrics import  confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./RNA_seq.csv\")\n",
    "dataT=np.array(data)\n",
    "data=dataT.T\n",
    "co=data[0]\n",
    "data1=np.delete(data,0,axis=0)\n",
    "data=data1\n",
    "datadf= pd.DataFrame(data=data[0:,0:],columns=co)\n",
    "datadf.head()\n",
    "data=datadf\n",
    "data= data.replace(\"NOTLC\",value=0)\n",
    "data= data.replace(\"LC\",value=1)\n",
    "X=data.drop(['Group'],axis=1)\n",
    "y=data['Group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "column=X.columns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X=sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.DataFrame(data=X,columns=column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape : (878, 60660)\n",
      "Test shape: (220, 60660)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42,stratify=None)\n",
    "print(f'Train shape : {X_train.shape}\\nTest shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crosspredict(estimator,Xtrain,ytrain,cv):\n",
    "    print(\"cross-validate across the entire data set\")\n",
    "    y_pred_cross=cross_val_predict(estimator,Xtrain,ytrain,cv=cv)\n",
    "    confusion_cross=confusion_matrix(ytrain,y_pred_cross)\n",
    "    a=accuracy_score(ytrain,y_pred_cross)\n",
    "    p=precision_score(ytrain, y_pred_cross)\n",
    "    r=recall_score(ytrain, y_pred_cross)\n",
    "    f1=f1_score(ytrain, y_pred_cross)\n",
    "    wf1=f1_score(ytrain, y_pred_cross, average='weighted')\n",
    "    #auc=roc_auc_score(ytrain,estimator.predict_proba(Xtrain)[:,1])\n",
    "    print('the confusion_matrix of the model is : \\n',confusion_cross)\n",
    "    print('the accuracy of the model is : ',a)\n",
    "    print(\"the precision score of the model is : \", p)\n",
    "    print(\"the recall score of the model is :\", r)\n",
    "    print('the f1_score of the model  is :',f1)\n",
    "    print('the weighted_f1 of the model is :',wf1)\n",
    "    print('the classification_report is :\\n',classification_report(ytrain, y_pred_cross,digits=4))\n",
    "    #print('the auc is :',auc)\n",
    "    return a,p,r,f1,wf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "class MyEstimator(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, model, mask) -> None:\n",
    "        super().__init__()\n",
    "        self.mask = mask\n",
    "        self.model = model\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.model.fit(X[self.mask],y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X[self.mask])\n",
    "    \n",
    "    def predict_proba(self,X):\n",
    "        return self.model.predict_proba(X[self.mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "over_samples = SMOTE(random_state =42)\n",
    "X_smote, y_smote= over_samples.fit_sample(X, y)\n",
    "X_smote=pd.DataFrame(data=X_smote,columns=column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validate across the entire data set\n",
      "the confusion_matrix of the model is : \n",
      " [[994   0]\n",
      " [  1 993]]\n",
      "the accuracy of the model is :  0.9994969818913481\n",
      "the precision score of the model is :  1.0\n",
      "the recall score of the model is : 0.9989939637826962\n",
      "the f1_score of the model  is : 0.9994967287367891\n",
      "the weighted_f1 of the model is : 0.9994969817640708\n",
      "the classification_report is :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9990    1.0000    0.9995       994\n",
      "           1     1.0000    0.9990    0.9995       994\n",
      "\n",
      "    accuracy                         0.9995      1988\n",
      "   macro avg     0.9995    0.9995    0.9995      1988\n",
      "weighted avg     0.9995    0.9995    0.9995      1988\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import *\n",
    "sel_seq_dt_mask=['ENSG00000003147.19','ENSG00000004455.17','ENSG00000006327.14','ENSG00000018510.17','ENSG00000067064.11','ENSG00000154813.10','ENSG00000204305.14','ENSG00000234425.1','ENSG00000262772.2','ENSG00000272477.1']\n",
    "sel_seq_rf_mask=['ENSG00000106089.12', 'ENSG00000204305.14', 'ENSG00000223982.3','ENSG00000229693.2']\n",
    "sel_seq_ada_mask=['ENSG00000000005.6', 'ENSG00000002933.9','ENSG00000019144.19', 'ENSG00000070366.14','ENSG00000091262.16','ENSG00000106089.12','ENSG00000204305.14','ENSG00000233117.4']\n",
    "sel_seq_gb_mask=['ENSG00000000005.6','ENSG00000000971.16', 'ENSG00000001631.16','ENSG00000002587.10', 'ENSG00000004779.10','ENSG00000106089.12', 'ENSG00000144130.11', 'ENSG00000204305.14']\n",
    "sel_seq_xgb_mask=['ENSG00000106089.12','ENSG00000170989.10', 'ENSG00000204305.14']\n",
    "sel_seq_KN_mask=['ENSG00000012983.11','ENSG00000106089.12','ENSG00000158578.21','ENSG00000204305.14','ENSG00000214796.8', 'ENSG00000277878.1']\n",
    "sel_seq_Lightgbm_mask=['ENSG00000002834.18','ENSG00000106089.12', 'ENSG00000170989.10','ENSG00000204305.14']\n",
    "sel_seq_SVC_mask=['ENSG00000002726.21','ENSG00000039068.19','ENSG00000120279.6','ENSG00000158578.21','ENSG00000182685.7','ENSG00000204305.14']\n",
    "sel_seq_GNB_mask=['ENSG00000011052.21', 'ENSG00000052841.15','ENSG00000062194.16', 'ENSG00000068001.14', 'ENSG00000102871.16','ENSG00000124532.15', 'ENSG00000204305.14', 'ENSG00000227066.2']\n",
    "sel_seq_lr_mask=['ENSG00000102547.19','ENSG00000135604.10','ENSG00000159352.16','ENSG00000224215.1','ENSG00000234481.2','ENSG00000252275.1','ENSG00000271555.1']\n",
    "\n",
    "feature=list(set(sel_seq_dt_mask+sel_seq_rf_mask+sel_seq_ada_mask+sel_seq_xgb_mask+sel_seq_GNB_mask))\n",
    "\n",
    "model_dt_fs = MyEstimator(DecisionTreeClassifier(), sel_seq_dt_mask)\n",
    "model_rf_fs = MyEstimator(RandomForestClassifier(), sel_seq_rf_mask)\n",
    "model_ada_fs = MyEstimator(AdaBoostClassifier(), sel_seq_ada_mask)\n",
    "model_gb_fs = MyEstimator(GradientBoostingClassifier(), sel_seq_gb_mask)\n",
    "model_xgb_fs = MyEstimator(XGBClassifier(), mask=sel_seq_xgb_mask)\n",
    "model_KN_fs = MyEstimator(KNeighborsClassifier(), mask=sel_seq_KN_mask)\n",
    "model_Lightgbm_fs = MyEstimator(lgb.LGBMClassifier(), mask=sel_seq_Lightgbm_mask)\n",
    "model_SVC_fs = MyEstimator(SVC(),mask=sel_seq_SVC_mask)\n",
    "model_GNB_fs = MyEstimator(GaussianNB(),mask=sel_seq_GNB_mask)\n",
    "model_lr_fs = MyEstimator(LogisticRegression(),mask=sel_seq_lr_mask)\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "model_voting_cross = VotingClassifier([  \n",
    "    (\"dt\",model_dt_fs),\n",
    "    (\"rf\",model_rf_fs ),\n",
    "    (\"ada\", model_ada_fs),\n",
    "    (\"xgb\", model_xgb_fs),\n",
    "    (\"GNB\",model_GNB_fs),\n",
    "], voting=\"hard\")\n",
    "a,b,c,d,e=crosspredict(model_voting_cross,X_smote,y_smote,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validate across the entire data set\n",
      "the confusion_matrix of the model is : \n",
      " [[994   0]\n",
      " [  1 993]]\n",
      "the accuracy of the model is :  0.9994969818913481\n",
      "the precision score of the model is :  1.0\n",
      "the recall score of the model is : 0.9989939637826962\n",
      "the f1_score of the model  is : 0.9994967287367891\n",
      "the weighted_f1 of the model is : 0.9994969817640708\n",
      "the classification_report is :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9990    1.0000    0.9995       994\n",
      "           1     1.0000    0.9990    0.9995       994\n",
      "\n",
      "    accuracy                         0.9995      1988\n",
      "   macro avg     0.9995    0.9995    0.9995      1988\n",
      "weighted avg     0.9995    0.9995    0.9995      1988\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.classifier import StackingClassifier\n",
    "model_Stacking_cross = StackingClassifier(classifiers=[\n",
    "    (model_dt_fs),\n",
    "    (model_rf_fs ),\n",
    "    (model_ada_fs),\n",
    "    (model_xgb_fs),\n",
    "    (model_GNB_fs),\n",
    "],meta_classifier=LogisticRegression(C=0.1))\n",
    "\n",
    "a,b,c,d,e=crosspredict(model_Stacking_cross,X_smote,y_smote,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[model_dt_fs,model_rf_fs,model_ada_fs,model_gb_fs,model_xgb_fs,model_KN_fs,model_Lightgbm_fs,model_SVC_fs,model_GNB_fs,model_lr_fs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model is: MyEstimator(mask=['ENSG00000003147.19', 'ENSG00000004455.17',\n",
      "                  'ENSG00000006327.14', 'ENSG00000018510.17',\n",
      "                  'ENSG00000067064.11', 'ENSG00000154813.10',\n",
      "                  'ENSG00000204305.14', 'ENSG00000234425.1',\n",
      "                  'ENSG00000262772.2', 'ENSG00000272477.1'],\n",
      "            model=DecisionTreeClassifier())\n",
      "cross-validate across the entire data set\n",
      "the confusion_matrix of the model is : \n",
      " [[989   5]\n",
      " [  6 988]]\n",
      "the accuracy of the model is :  0.994466800804829\n",
      "the precision score of the model is :  0.9949647532729103\n",
      "the recall score of the model is : 0.993963782696177\n",
      "the f1_score of the model  is : 0.9944640161046804\n",
      "the weighted_f1 of the model is : 0.9944667994047786\n",
      "the classification_report is :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9940    0.9950    0.9945       994\n",
      "           1     0.9950    0.9940    0.9945       994\n",
      "\n",
      "    accuracy                         0.9945      1988\n",
      "   macro avg     0.9945    0.9945    0.9945      1988\n",
      "weighted avg     0.9945    0.9945    0.9945      1988\n",
      "\n",
      "the model is: MyEstimator(mask=['ENSG00000106089.12', 'ENSG00000204305.14',\n",
      "                  'ENSG00000223982.3', 'ENSG00000229693.2'],\n",
      "            model=RandomForestClassifier())\n",
      "cross-validate across the entire data set\n",
      "the confusion_matrix of the model is : \n",
      " [[993   1]\n",
      " [  1 993]]\n",
      "the accuracy of the model is :  0.9989939637826962\n",
      "the precision score of the model is :  0.9989939637826962\n",
      "the recall score of the model is : 0.9989939637826962\n",
      "the f1_score of the model  is : 0.9989939637826962\n",
      "the weighted_f1 of the model is : 0.9989939637826962\n",
      "the classification_report is :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9990    0.9990    0.9990       994\n",
      "           1     0.9990    0.9990    0.9990       994\n",
      "\n",
      "    accuracy                         0.9990      1988\n",
      "   macro avg     0.9990    0.9990    0.9990      1988\n",
      "weighted avg     0.9990    0.9990    0.9990      1988\n",
      "\n",
      "the model is: MyEstimator(mask=['ENSG00000000005.6', 'ENSG00000002933.9',\n",
      "                  'ENSG00000019144.19', 'ENSG00000070366.14',\n",
      "                  'ENSG00000091262.16', 'ENSG00000106089.12',\n",
      "                  'ENSG00000204305.14', 'ENSG00000233117.4'],\n",
      "            model=AdaBoostClassifier())\n",
      "cross-validate across the entire data set\n",
      "the confusion_matrix of the model is : \n",
      " [[994   0]\n",
      " [  3 991]]\n",
      "the accuracy of the model is :  0.9984909456740443\n",
      "the precision score of the model is :  1.0\n",
      "the recall score of the model is : 0.9969818913480886\n",
      "the f1_score of the model  is : 0.9984886649874055\n",
      "the weighted_f1 of the model is : 0.9984909422375501\n",
      "the classification_report is :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9970    1.0000    0.9985       994\n",
      "           1     1.0000    0.9970    0.9985       994\n",
      "\n",
      "    accuracy                         0.9985      1988\n",
      "   macro avg     0.9985    0.9985    0.9985      1988\n",
      "weighted avg     0.9985    0.9985    0.9985      1988\n",
      "\n",
      "the model is: MyEstimator(mask=['ENSG00000000005.6', 'ENSG00000000971.16',\n",
      "                  'ENSG00000001631.16', 'ENSG00000002587.10',\n",
      "                  'ENSG00000004779.10', 'ENSG00000106089.12',\n",
      "                  'ENSG00000144130.11', 'ENSG00000204305.14'],\n",
      "            model=GradientBoostingClassifier())\n",
      "cross-validate across the entire data set\n",
      "the confusion_matrix of the model is : \n",
      " [[992   2]\n",
      " [  4 990]]\n",
      "the accuracy of the model is :  0.9969818913480886\n",
      "the precision score of the model is :  0.9979838709677419\n",
      "the recall score of the model is : 0.9959758551307847\n",
      "the f1_score of the model  is : 0.9969788519637462\n",
      "the weighted_f1 of the model is : 0.9969818882934309\n",
      "the classification_report is :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9960    0.9980    0.9970       994\n",
      "           1     0.9980    0.9960    0.9970       994\n",
      "\n",
      "    accuracy                         0.9970      1988\n",
      "   macro avg     0.9970    0.9970    0.9970      1988\n",
      "weighted avg     0.9970    0.9970    0.9970      1988\n",
      "\n",
      "the model is: MyEstimator(mask=['ENSG00000106089.12', 'ENSG00000170989.10',\n",
      "                  'ENSG00000204305.14'],\n",
      "            model=XGBClassifier(base_score=None, booster=None,\n",
      "                                colsample_bylevel=None, colsample_bynode=None,\n",
      "                                colsample_bytree=None, gamma=None, gpu_id=None,\n",
      "                                importance_type='gain',\n",
      "                                interaction_constraints=None,\n",
      "                                learning_rate=None, max_delta_step=None,\n",
      "                                max_depth=None, min_child_weight=None,\n",
      "                                missing=nan, monotone_constraints=None,\n",
      "                                n_estimators=100, n_jobs=None,\n",
      "                                num_parallel_tree=None, random_state=None,\n",
      "                                reg_alpha=None, reg_lambda=None,\n",
      "                                scale_pos_weight=None, subsample=None,\n",
      "                                tree_method=None, validate_parameters=None,\n",
      "                                verbosity=None))\n",
      "cross-validate across the entire data set\n",
      "the confusion_matrix of the model is : \n",
      " [[994   0]\n",
      " [  3 991]]\n",
      "the accuracy of the model is :  0.9984909456740443\n",
      "the precision score of the model is :  1.0\n",
      "the recall score of the model is : 0.9969818913480886\n",
      "the f1_score of the model  is : 0.9984886649874055\n",
      "the weighted_f1 of the model is : 0.9984909422375501\n",
      "the classification_report is :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9970    1.0000    0.9985       994\n",
      "           1     1.0000    0.9970    0.9985       994\n",
      "\n",
      "    accuracy                         0.9985      1988\n",
      "   macro avg     0.9985    0.9985    0.9985      1988\n",
      "weighted avg     0.9985    0.9985    0.9985      1988\n",
      "\n",
      "the model is: MyEstimator(mask=['ENSG00000012983.11', 'ENSG00000106089.12',\n",
      "                  'ENSG00000158578.21', 'ENSG00000204305.14',\n",
      "                  'ENSG00000214796.8', 'ENSG00000277878.1'],\n",
      "            model=KNeighborsClassifier())\n",
      "cross-validate across the entire data set\n",
      "the confusion_matrix of the model is : \n",
      " [[994   0]\n",
      " [ 11 983]]\n",
      "the accuracy of the model is :  0.994466800804829\n",
      "the precision score of the model is :  1.0\n",
      "the recall score of the model is : 0.9889336016096579\n",
      "the f1_score of the model  is : 0.9944360141628731\n",
      "the weighted_f1 of the model is : 0.9944666313935926\n",
      "the classification_report is :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9891    1.0000    0.9945       994\n",
      "           1     1.0000    0.9889    0.9944       994\n",
      "\n",
      "    accuracy                         0.9945      1988\n",
      "   macro avg     0.9945    0.9945    0.9945      1988\n",
      "weighted avg     0.9945    0.9945    0.9945      1988\n",
      "\n",
      "the model is: MyEstimator(mask=['ENSG00000002834.18', 'ENSG00000106089.12',\n",
      "                  'ENSG00000170989.10', 'ENSG00000204305.14'],\n",
      "            model=LGBMClassifier())\n",
      "cross-validate across the entire data set\n",
      "the confusion_matrix of the model is : \n",
      " [[992   2]\n",
      " [  3 991]]\n",
      "the accuracy of the model is :  0.9974849094567404\n",
      "the precision score of the model is :  0.9979859013091642\n",
      "the recall score of the model is : 0.9969818913480886\n",
      "the f1_score of the model  is : 0.9974836436839458\n",
      "the weighted_f1 of the model is : 0.997484908820354\n",
      "the classification_report is :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9970    0.9980    0.9975       994\n",
      "           1     0.9980    0.9970    0.9975       994\n",
      "\n",
      "    accuracy                         0.9975      1988\n",
      "   macro avg     0.9975    0.9975    0.9975      1988\n",
      "weighted avg     0.9975    0.9975    0.9975      1988\n",
      "\n",
      "the model is: MyEstimator(mask=['ENSG00000002726.21', 'ENSG00000039068.19',\n",
      "                  'ENSG00000120279.6', 'ENSG00000158578.21',\n",
      "                  'ENSG00000182685.7', 'ENSG00000204305.14'],\n",
      "            model=SVC())\n",
      "cross-validate across the entire data set\n",
      "the confusion_matrix of the model is : \n",
      " [[994   0]\n",
      " [  6 988]]\n",
      "the accuracy of the model is :  0.9969818913480886\n",
      "the precision score of the model is :  1.0\n",
      "the recall score of the model is : 0.993963782696177\n",
      "the f1_score of the model  is : 0.9969727547931382\n",
      "the weighted_f1 of the model is : 0.9969818638559472\n",
      "the classification_report is :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9940    1.0000    0.9970       994\n",
      "           1     1.0000    0.9940    0.9970       994\n",
      "\n",
      "    accuracy                         0.9970      1988\n",
      "   macro avg     0.9970    0.9970    0.9970      1988\n",
      "weighted avg     0.9970    0.9970    0.9970      1988\n",
      "\n",
      "the model is: MyEstimator(mask=['ENSG00000011052.21', 'ENSG00000052841.15',\n",
      "                  'ENSG00000062194.16', 'ENSG00000068001.14',\n",
      "                  'ENSG00000102871.16', 'ENSG00000124532.15',\n",
      "                  'ENSG00000204305.14', 'ENSG00000227066.2'],\n",
      "            model=GaussianNB())\n",
      "cross-validate across the entire data set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the confusion_matrix of the model is : \n",
      " [[994   0]\n",
      " [234 760]]\n",
      "the accuracy of the model is :  0.8822937625754527\n",
      "the precision score of the model is :  1.0\n",
      "the recall score of the model is : 0.7645875251509054\n",
      "the f1_score of the model  is : 0.8665906499429874\n",
      "the weighted_f1 of the model is : 0.8806400594449411\n",
      "the classification_report is :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8094    1.0000    0.8947       994\n",
      "           1     1.0000    0.7646    0.8666       994\n",
      "\n",
      "    accuracy                         0.8823      1988\n",
      "   macro avg     0.9047    0.8823    0.8806      1988\n",
      "weighted avg     0.9047    0.8823    0.8806      1988\n",
      "\n",
      "the model is: MyEstimator(mask=['ENSG00000102547.19', 'ENSG00000135604.10',\n",
      "                  'ENSG00000159352.16', 'ENSG00000224215.1',\n",
      "                  'ENSG00000234481.2', 'ENSG00000252275.1',\n",
      "                  'ENSG00000271555.1'],\n",
      "            model=LogisticRegression())\n",
      "cross-validate across the entire data set\n",
      "the confusion_matrix of the model is : \n",
      " [[993   1]\n",
      " [  3 991]]\n",
      "the accuracy of the model is :  0.9979879275653923\n",
      "the precision score of the model is :  0.998991935483871\n",
      "the recall score of the model is : 0.9969818913480886\n",
      "the f1_score of the model  is : 0.9979859013091642\n",
      "the weighted_f1 of the model is : 0.9979879255289539\n",
      "the classification_report is :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9970    0.9990    0.9980       994\n",
      "           1     0.9990    0.9970    0.9980       994\n",
      "\n",
      "    accuracy                         0.9980      1988\n",
      "   macro avg     0.9980    0.9980    0.9980      1988\n",
      "weighted avg     0.9980    0.9980    0.9980      1988\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in models:\n",
    "    print(\"the model is:\",i)\n",
    "    a,b,c,d,e=crosspredict(i,X_smote,y_smote,10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
